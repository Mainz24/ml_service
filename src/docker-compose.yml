version: "3.8"

services:
  app:
    build: app/
    container_name: backend-app
    restart: unless-stopped
#    restart: no
#    command: ["python", "/app/src/api.py"]
    env_file:
      - .env
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - .:/src
#    healthcheck:
#      test: [ "CMD", "curl", "-f", "http://localhost:8000/health" ]
#      interval: 10s
#      timeout: 5s
#      retries: 3
#      start_period: 10s
    #    ports:
#      - "8080:8080"
    environment:
      PYTHONPATH: /src
#      WORKDIR: /app
    networks:
      - ml_service

  web-proxy:
    image: nginx:1.29
    container_name: backend-nginx
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "${WEB_PROXY1}:80"
      - "${WEB_PROXY2}:443"
#    healthcheck:
#      test: [ "CMD", "curl", "-f", "http://localhost" ]
#      interval: 10s
#      timeout: 5s
#      retries: 3
#      start_period: 10s
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./config/nginx.conf:/etc/nginx/nginx.conf
    networks:
      - ml_service
  postgres:
    image: postgres:16-alpine
    container_name: backend_bd
    restart: on-failure
    env_file:
      - .env
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
      POSTGRES_DB: ${DB_NAME}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_PASS}"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - ml_service
  rabbitmq:
    image: rabbitmq:4.2-management-alpine
    container_name: backend_rabbitmq
    hostname: rabbitmq
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - "${MQ_PORT1}:15672"
      - "${MQ_PORT2}:5672"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS}
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    depends_on:
      app:
         condition: service_started
    networks:
      - ml_service
  ml-worker:
    build: worker/ml/
#    container_name: backend-ml
    restart: unless-stopped
    command: >
      /usr/bin/wait_for_mq.sh
      python -u ./worker/ml/ml_worker.py
    env_file:
      - .env
    depends_on:
        rabbitmq:
          condition: service_healthy
    volumes:
      - .:/src
      - hf_cache_volume:/root/.cache/huggingface/hub
    environment:
      PYTHONPATH: /src
#      WORKDIR: /app
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
    networks:
      - ml_service
  db-worker:
    build: worker/db/
    container_name: backend-db-worker
    restart: unless-stopped
    command:  >
      /usr/bin/wait_for_mq.sh
      python -u ./worker/db/db_worker.py
    env_file:
      - .env
    depends_on:
        rabbitmq:
          condition: service_healthy
    volumes:
      - .:/src
    environment:
      PYTHONPATH: /src
#      WORKDIR: /app
    networks:
      - ml_service
#  notify-worker:
#    build: worker/
#    container_name: backend-notify-worker
#    restart: unless-stopped
#    command: >
#      /usr/bin/wait_for_mq.sh
#      python -u ./worker/worker/notify_worker_app.py
#    env_file:
#      - .env
#    depends_on:
#        rabbitmq:
#          condition: service_healthy
#    volumes:
#      - .:/src
#    environment:
#      PYTHONPATH: /src
##      WORKDIR: /app
#    networks:
#      - ml_service

volumes:
  postgres_data:
  rabbitmq_data:
  hf_cache_volume:

networks:
  ml_service:
    name: ml_service
    driver: bridge